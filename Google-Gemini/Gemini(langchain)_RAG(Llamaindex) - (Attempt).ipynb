{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xBawGhJ8Okv"
   },
   "source": [
    "# Apresentação:\n",
    "\n",
    "\n",
    "**Documentações:**\n",
    "\n",
    "Langchain: https://python.langchain.com/v0.2/docs/introduction/\n",
    "\n",
    "LlamaIndex:https://docs.llamaindex.ai/en/stable/\n",
    "\n",
    "Gemini: https://ai.google.dev/gemini-api/docs?hl=pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 235389,
     "status": "ok",
     "timestamp": 1716424107964,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "AM2AKOM6SEd-",
    "outputId": "9ac9335c-cca7-4a91-f3bf-718a2c4da9cb"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-google-genai\n",
    "!pip install cohere\n",
    "!pip install tiktoken\n",
    "!pip install vectordb2\n",
    "!pip install tqdm\n",
    "!pip install langchain\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ThRclE1QfM_"
   },
   "source": [
    "# Comunicando com a API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1716424107965,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "iQo3owSUQ0Jw"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1716424107965,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "9i8DCqevQIQ3"
   },
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = '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'\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyAOnPRrERpX8IOIlOYDAXbb0vwvhYkrTVo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8JEtupgRS5x"
   },
   "source": [
    "# Modelo Utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2423,
     "status": "ok",
     "timestamp": 1716424110385,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "Qv03TYSvQv18"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import pathlib\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1716424110385,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "gF5VZyWDW2YT"
   },
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1716424110385,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "vW1wnXgbaLBK"
   },
   "outputs": [],
   "source": [
    "historico = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1716424110386,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "sn3Z19F3UX-x"
   },
   "outputs": [],
   "source": [
    "def question(url=None):\n",
    "    pergunta = input('Digite sua pergunta:\\n')\n",
    "\n",
    "    if url:\n",
    "        # Usar modelo que aceita imagens quando uma URL de imagem é fornecida\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "        message = HumanMessage(content=\n",
    "         [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": pergunta,\n",
    "            },  # You can optionally provide text parts\n",
    "            {\"type\": \"image_url\", \"image_url\": url},\n",
    "         ])\n",
    "        resposta = llm.invoke([message])\n",
    "    else:\n",
    "        # Usar modelo de texto quando nenhuma imagem é fornecida\n",
    "        message = [{'role': 'user', 'content': pergunta}]\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "        resposta = llm.invoke(message)\n",
    "\n",
    "    historico.append(pergunta)  # Adiciona a mensagem ao histórico\n",
    "    return to_markdown(resposta.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "executionInfo": {
     "elapsed": 9922,
     "status": "ok",
     "timestamp": 1716424144804,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "m6G1H80K2bw9",
    "outputId": "f641fff6-4242-450d-ec1a-f3f48f23792d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite sua pergunta:\n",
      "faleme sobre você.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Sou Gemini, um modelo de linguagem de IA multimodal treinado pelo Google. Meu objetivo é fornecer informações abrangentes e úteis às pessoas que interagem comigo.\n",
       "> \n",
       "> Como modelo de linguagem de IA, não tenho experiências pessoais ou consciência própria, portanto não tenho uma história ou vida pessoal para compartilhar. No entanto, posso fornecer informações sobre uma ampla gama de tópicos, incluindo:\n",
       "> \n",
       "> * **Eventos atuais e notícias:** Posso fornecer atualizações sobre eventos globais e nacionais recentes.\n",
       "> * **Ciência e tecnologia:** Tenho conhecimento de avanços científicos e tecnológicos, incluindo descobertas e inovações.\n",
       "> * **Artes e cultura:** Posso discutir tendências e figuras importantes nas artes, incluindo literatura, música e cinema.\n",
       "> * **História e geografia:** Tenho acesso a informações sobre eventos históricos e dados geográficos.\n",
       "> * **Línguas e tradução:** Posso traduzir textos e responder perguntas sobre diferentes idiomas.\n",
       "> * **Matemática e estatística:** Posso realizar cálculos e fornecer informações estatísticas.\n",
       "> \n",
       "> Estou constantemente aprendendo e aprimorando minhas habilidades, e meu conhecimento é atualizado regularmente. Meu objetivo é ser um recurso valioso para as pessoas, fornecendo respostas informativas e confiáveis às suas perguntas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4HF4UgX3Uq0"
   },
   "source": [
    "# Rag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1716424110386,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "Mgr1K79iyvxa"
   },
   "outputs": [],
   "source": [
    "# Bibliotecas para requisição e tratamento do texto base:\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1716424110783,
     "user": {
      "displayName": "André Amorim",
      "userId": "04859568826717067647"
     },
     "user_tz": 180
    },
    "id": "kHMeiomM3V8G"
   },
   "outputs": [],
   "source": [
    "# Importando o Texto bruto:\n",
    "bruto_text = requests.get('https://raw.githubusercontent.com/abjur/constituicao/main/CONSTITUICAO.md').text\n",
    "\n",
    "# Otimização do Texto:\n",
    "padrao_capitulo = r'^##\\s+(.*)$' # A ideia é pegar tudo que vem depois do ##\n",
    "sections = re.split(padrao_capitulo, bruto_text, flags=re.MULTILINE)\n",
    "sections = [section.strip() for section in sections[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOB8XFj_741S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP2QkQuziYuxgc4RJ9wKooS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
