{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1rdnnwNUaG1ouG2Hn7BLZl6TJqAhB5ISm","timestamp":1716334457512}],"authorship_tag":"ABX9TyOy1dyqjYuV7uiIp75liqUQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Apresentação:\n","\n","    A ideia aqui é construir um modelo de LLM implementando o RAG,\n","    Retrieval Augmented Generation. Visando essa efervecência de\n","    concursos públicos, a ideia aqui é criar um modelo especializado\n","    em direito, vamos começar com direito constitucional.\n","\n","Nota:\n","\n","    As ideias tratadas aqui que já tenham sido tratadas antes, não\n","    serão reescritas aqui, então, caso haja interesse, busque os códigos\n","    anteriores no repositorio do github."],"metadata":{"id":"po2TFAstM7rM"}},{"cell_type":"code","source":["# Instalações Necessárias:\n","!pip install openai\n","!pip install cohere\n","!pip install tiktoken\n","!pip install vectordb2\n","!pip install tqdm\n","!pip install langchain\n","!pip install transformers[torch]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSp1j6w1NIKa","executionInfo":{"status":"ok","timestamp":1707843057504,"user_tz":180,"elapsed":74214,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"abdc371b-23e5-44ed-e264-f827b945d5e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.47)\n","Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n","Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n","Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.3)\n","Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.11.0)\n","Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.18)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Requirement already satisfied: vectordb2 in /usr/local/lib/python3.10/dist-packages (0.1.9)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.1.0+cu121)\n","Requirement already satisfied: transformers>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (4.35.2)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.2.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.11.4)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.3.1)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.7.4)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.15.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (2.1.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (4.66.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (0.1.99)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (9.4.0)\n","Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->vectordb2) (0.16.1)\n","Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (4.23.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.4.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.57.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->vectordb2) (2.1.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->vectordb2) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->vectordb2) (1.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.3.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.6)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.19)\n","Requirement already satisfied: langchain-core<0.2,>=0.1.22 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.22)\n","Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.87)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (3.7.1)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"]}]},{"cell_type":"markdown","source":["# Implementando o RAG:\n","\n","    RAG é Retrieval Augmented Generation é um método de melhoria de um\n","    LLM baseado no que eu vou chamar aqui de \"revalidação\". Antes do\n","    modelo dar a resposta, a ideia é ele validar essa resposta num conjunto\n","    de documentos especializados.\n","\n","    É como se, antes do modelo dar a resposta, ele fosse checar a resposta\n","    com um especialista."],"metadata":{"id":"5qOeuTe4NGl8"}},{"cell_type":"markdown","source":["**Preparando o texto base**"],"metadata":{"id":"GgmmYaWeQZtX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"En0F0izGM6L2","executionInfo":{"status":"ok","timestamp":1707842871370,"user_tz":180,"elapsed":49868,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"8554b393-83aa-42b5-8b49-6195a4bd07f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+http://github.com/vioshyvo/mrpt/\n","  Cloning http://github.com/vioshyvo/mrpt/ to /tmp/pip-req-build-v8ks6qlb\n","  Running command git clone --filter=blob:none --quiet http://github.com/vioshyvo/mrpt/ /tmp/pip-req-build-v8ks6qlb\n","  warning: redirecting to https://github.com/vioshyvo/mrpt/\n","  Resolved http://github.com/vioshyvo/mrpt/ to commit 88cc6f40782ca0f8de7491279766ded01d767861\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from mrpt==1.0) (1.23.5)\n","Building wheels for collected packages: mrpt\n","  Building wheel for mrpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mrpt: filename=mrpt-1.0-cp310-cp310-linux_x86_64.whl size=1561746 sha256=bbc28dc9bc2c0595047c4b35e4ca53c84995ff017c8689fee8de634aea4f9df6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-tp38aw78/wheels/61/f0/46/8fd08e2aa4be121079dc3ef4634352680489c4028bdb57e4de\n","Successfully built mrpt\n","Installing collected packages: mrpt\n","Successfully installed mrpt-1.0\n"]}],"source":["# MRPT - fast nearest neighbor search with random projection\n","!pip install git+http://github.com/vioshyvo/mrpt/"]},{"cell_type":"code","source":["# Bibliotecas para requisição e tratamento do texto base:\n","import re\n","import requests"],"metadata":{"id":"BOeHRxc6NFb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importando o Texto bruto:\n","bruto_text = requests.get('https://raw.githubusercontent.com/abjur/constituicao/main/CONSTITUICAO.md').text\n","\n","# Otimização do Texto:\n","padrao_capitulo = r'^##\\s+(.*)$' # A ideia é pegar tudo que vem depois do ##\n","sections = re.split(padrao_capitulo, bruto_text, flags=re.MULTILINE)\n","sections = [section.strip() for section in sections[1:]]"],"metadata":{"id":"r662fDdoP_tG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Indexando os dados no VectorDB**"],"metadata":{"id":"-3I4PVgdQzQJ"}},{"cell_type":"code","source":["from tqdm import tqdm\n","from vectordb import Memory\n","from langchain.text_splitter import MarkdownHeaderTextSplitter"],"metadata":{"id":"rclUy_RYQPUu","colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"status":"error","timestamp":1707843230016,"user_tz":180,"elapsed":459,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"49b2030d-e112-40a2-cfbf-887c82c18233"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'Memory' from 'vectordb' (/usr/local/lib/python3.10/dist-packages/vectordb/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-ca4ba1ba5480>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvectordb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarkdownHeaderTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Memory' from 'vectordb' (/usr/local/lib/python3.10/dist-packages/vectordb/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# Instanciando o SGBD:\n","memory = Memory(chunking_strategy={'mode':'sliding_window',\n","                                   'window_size':128, # Chunk_size\n","                                   'overlap':8 # Chunk Overlap / Janela Deslizante\n","                                   })"],"metadata":{"id":"TCT7X6itQtdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizando as strings:\n","padrao_capitulo = [(\"##\",\"Capitulo\")]\n","markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=padrao_capitulo)\n","sections = markdown_splitter.split_text(bruto_text)"],"metadata":{"id":"tq7dIuGPRXDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Indexando os dados:\n","for i in tqdm(range(0,len(sections))):\n","  capitulo = sections[i].metadata\n","  texto = sections[i].page_content\n","\n","  metadata = {'capitulo':capitulo,\n","              'origem':'Constituição Federal'}\n","\n","  memory.save(texto,metadata)"],"metadata":{"id":"8I6kUtshRKif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Teste de Pesquisa:\n","memory.search('direitos dos trabalhadores', top_n=5)"],"metadata":{"id":"1crD-M7fRRL3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Construção do LLM:"],"metadata":{"id":"Q9-5dLTSUY06"}},{"cell_type":"code","source":["#import nltk\n","#import pathlib"],"metadata":{"id":"v6Voc3vbWwP5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#nltk.download('machado', download_dir='../data/gpt/raw')\n","#\n","#!mv ../data/gpt/raw/corpora/machado.zip ../data/gpt/raw/machado.zip\n","#!unzip ../data/gpt/raw/machado.zip -d ../data/gpt/raw\n","#!rm -R ../data/gpt/raw/corpora\n","#!rm ../data/gpt/raw/machado.zip"],"metadata":{"id":"dHuBU9MpW2mS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Abrindo o arquivo para extrair o conteudo:\n","#with open('../data/gpt/raw/machado/contos/macn001.txt', 'r', encoding='iso-8859-1') as f:\n","#    lines = f.read().splitlines()\n","#\n","## Juntando todas os livros\n","#text = []\n","#for text_path in sorted(pathlib.Path(\"../data/gpt/raw/machado/\").rglob(\"*.txt\")):\n","#    with open(text_path, 'r', encoding='iso-8859-1') as f:\n","#        lines = f.read().splitlines()\n","#    text += lines\n","#\n","#text = \" \".join(text)\n","#\n","#with open(\"../data/raw/machado-all.txt\", \"w\") as output:\n","#     output.write(text)"],"metadata":{"id":"OwOJn9I6Wuan"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#precisamos de um corpus bem robusto, porém não tão gigante\n","!wget -O ./sample_data/crepusculoDosIdolos.txt https://raw.githubusercontent.com/mfmarlonferrari/NietzscheLLM/main/crepusculoDosIdolos.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lB6JCPsZUk08","executionInfo":{"status":"ok","timestamp":1707087124774,"user_tz":180,"elapsed":662,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"734ee1cd-1c7b-4544-943a-a1d67dd5930d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-04 22:51:58--  https://raw.githubusercontent.com/mfmarlonferrari/NietzscheLLM/main/crepusculoDosIdolos.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 162098 (158K) [text/plain]\n","Saving to: ‘./sample_data/crepusculoDosIdolos.txt’\n","\n","./sample_data/crepu 100%[===================>] 158.30K  --.-KB/s    in 0.03s   \n","\n","2024-02-04 22:51:58 (5.45 MB/s) - ‘./sample_data/crepusculoDosIdolos.txt’ saved [162098/162098]\n","\n"]}]},{"cell_type":"code","source":["PATH = './sample_data/'\n","dados_treino = 'crepusculoDosIdolos.txt'"],"metadata":{"id":"wggUIcJwUlQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Criando o tonkenizer baseado no algoritmo BPE\n","from tokenizers.implementations import ByteLevelBPETokenizer\n","from tokenizers.processors import BertProcessing\n","from transformers import (RobertaTokenizer,RobertaForMaskedLM,\n","                          RobertaConfig,LineByLineTextDataset,\n","                          DataCollatorForLanguageModeling,\n","                          Trainer, TrainingArguments,pipeline)"],"metadata":{"id":"P3WAJydZUu63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instanciando o modelo:\n","tokenizer = ByteLevelBPETokenizer()\n","\n","tokenizer.train(files=[PATH+dados_treino],vocab_size=52_000,\n","                min_frequency=2, special_tokens=[\n","                    \"<s>\",\n","                    \"<pad>\",\n","                    \"</s>\",\n","                    \"<unk>\",\n","                    \"<mask>\"])"],"metadata":{"id":"Iv12cej7Voos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Salvando modelo:\n","!rm -r ./sample_data/RAW_MODEL\n","!mkdir ./sample_data/RAW_MODEL\n","tokenizer.save_model(PATH+\"RAW_MODEL\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0urx5jfcU9bu","executionInfo":{"status":"ok","timestamp":1707087325388,"user_tz":180,"elapsed":399,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"0a17e423-2b51-42e1-f67b-b5bb7a03d157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove './sample_data/RAW_MODEL': No such file or directory\n"]},{"output_type":"execute_result","data":{"text/plain":["['./sample_data/RAW_MODEL/vocab.json', './sample_data/RAW_MODEL/merges.txt']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Instanciando modelo:\n","tokenizer = ByteLevelBPETokenizer(\n","    PATH+'RAW_MODEL'+'/vocab.json',\n","    PATH+'RAW_MODEL'+'/merges.txt')\n","\n","tokenizer._tokenizer.post_processor = BertProcessing(\n","    (\"</s\",tokenizer.token_to_id(\"</s>\")),\n","    (\"<s>\", tokenizer.token_to_id(\"<s>\"))\n",")\n","tokenizer.enable_truncation(max_length=512)"],"metadata":{"id":"b1CGjXP_U3zG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instanciando o Tokenizer do LLM escolhido:\n","tokenizer = RobertaTokenizer.from_pretrained(PATH+'RAW_MODEL',max_len=512)"],"metadata":{"id":"ni8-wYrvVWQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # Configurando o Transformer\n"," config = RobertaConfig(\n","     vocab_size=52_000,\n","     max_position_embeddings = 512,\n","     num_attention_heads = 12,\n","     num_hidden_layers = 6,\n","     type_vocab_size = 1)"],"metadata":{"id":"68hkEX6NWYid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instanciando Modelo:\n","model = RobertaForMaskedLM(config=config)"],"metadata":{"id":"2dqbXZL2WcEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizando os dados de Treino:\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=PATH+dados_treino,\n","    block_size=128\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnv-V6EcWd4m","executionInfo":{"status":"ok","timestamp":1707087648071,"user_tz":180,"elapsed":1907,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"2ea58ad5-8595-4676-86c3-f963c3896e5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Teste:\n","tokenizer.decode(dataset.examples[7]['input_ids'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"V44OZofjWks_","executionInfo":{"status":"ok","timestamp":1707087667382,"user_tz":180,"elapsed":345,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"55919052-bd14-4f7a-c774-48fbc07a0c8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<s>na escola bélica da vida — o que não me faz morrer me torna mais forte.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.1)"],"metadata":{"id":"flbI-0ZgWp19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Elementos do treinamento:\n","training_args = TrainingArguments(\n","    output_dir=PATH+'RAW_MODEL',\n","    overwrite_output_dir=True,\n","    num_train_epochs=1200,\n","    per_device_train_batch_size=64,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True)\n","\n","# Treinanmento:\n","Trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset)"],"metadata":{"id":"OyAZxoPsWyTm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit:\n","Trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"eD-nboqzW3Kd","executionInfo":{"status":"ok","timestamp":1707092992016,"user_tz":180,"elapsed":5263789,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"f1b8b36a-6c8f-4e12-c75b-24d6d998efd3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4800' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4800/4800 1:27:41, Epoch 1200/1200]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>6.550400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>5.226500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>4.217900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.230900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>2.382700</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.717100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>1.235900</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.919400</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.749400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4800, training_loss=2.7748859246571858, metrics={'train_runtime': 5263.4105, 'train_samples_per_second': 51.526, 'train_steps_per_second': 0.912, 'total_flos': 8992119855513600.0, 'train_loss': 2.7748859246571858, 'epoch': 1200.0})"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["Trainer.save_model(PATH+'RAW_MODEL')"],"metadata":{"id":"i_9jJHZBc2J2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testando o LLM:\n","fill_mask = pipeline(\n","    \"fill-mask\",\n","    model=PATH+'RAW_MODEL',\n","    tokenizer=PATH+'RAW_MODEL')\n","\n","# Primeiro teste:\n","texto = 'Digo que o amor é <mask>'\n","fill_mask(texto)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"otv_M0d8stUJ","executionInfo":{"status":"ok","timestamp":1707093491364,"user_tz":180,"elapsed":3823,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"387c6e4e-27c1-4685-bbbb-e916a5290d8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.05255282297730446,\n","  'token': 300,\n","  'token_str': ' um',\n","  'sequence': 'Digo que o amor é um'},\n"," {'score': 0.040366280823946,\n","  'token': 271,\n","  'token_str': ' de',\n","  'sequence': 'Digo que o amor é de'},\n"," {'score': 0.028334809467196465,\n","  'token': 961,\n","  'token_str': ' humanidade',\n","  'sequence': 'Digo que o amor é humanidade'},\n"," {'score': 0.0263307336717844,\n","  'token': 414,\n","  'token_str': ' —',\n","  'sequence': 'Digo que o amor é —'},\n"," {'score': 0.01727619580924511,\n","  'token': 575,\n","  'token_str': ' há',\n","  'sequence': 'Digo que o amor é há'}]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Segundo teste:\n","texto = 'O <mask> da moral: basear na lógica dos fracos'\n","fill_mask(texto)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZQ3YDL9s21F","executionInfo":{"status":"ok","timestamp":1707093517062,"user_tz":180,"elapsed":239,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"06ddaeda-48f9-48d6-a71b-c6d1494ba808"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.11579568684101105,\n","  'token': 800,\n","  'token_str': ' erro',\n","  'sequence': 'O erro da moral: basear na lógica dos fracos'},\n"," {'score': 0.033164724707603455,\n","  'token': 480,\n","  'token_str': ' \"',\n","  'sequence': 'O \" da moral: basear na lógica dos fracos'},\n"," {'score': 0.027672506868839264,\n","  'token': 459,\n","  'token_str': ' moral',\n","  'sequence': 'O moral da moral: basear na lógica dos fracos'},\n"," {'score': 0.015147262252867222,\n","  'token': 338,\n","  'token_str': ' por',\n","  'sequence': 'O por da moral: basear na lógica dos fracos'},\n"," {'score': 0.013160984963178635,\n","  'token': 389,\n","  'token_str': 'res',\n","  'sequence': 'Ores da moral: basear na lógica dos fracos'}]"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["from transformers import RobertaForCausalLM\n","\n","# Carregando o modelo treinado\n","modelo = RobertaForCausalLM.from_pretrained(PATH+'RAW_MODEL')\n","tokenizer = RobertaTokenizer.from_pretrained(PATH+'RAW_MODEL')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9feijMppuWh9","executionInfo":{"status":"ok","timestamp":1707094104049,"user_tz":180,"elapsed":3291,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"da6024ca-f874-4541-817c-516fb148c710"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"]}]},{"cell_type":"code","source":["# Função para gerar respostas\n","def gerar_resposta(texto_entrada, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95):\n","    # Tokenizando a entrada\n","    tokens = tokenizer.encode(texto_entrada, return_tensors=\"pt\")\n","\n","    # Obtendo a saída do modelo\n","    output = modelo.generate(tokens, max_length=max_length, num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size, top_k=top_k, top_p=top_p)\n","\n","    # Decodificando a saída\n","    resposta = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    return resposta"],"metadata":{"id":"YPW1PFEcu7CV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Exemplo de conversa\n","pergunta = \"Qual é o papel do presidente na Constituição Federal?\"\n","resposta = gerar_resposta(pergunta, max_length=200, num_beams=8, no_repeat_ngram_size=3, top_k=100, top_p=0.95)\n","resposta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"JYBAMpzqu-5V","executionInfo":{"status":"ok","timestamp":1707095149025,"user_tz":180,"elapsed":462366,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"27ba53ba-0965-46a5-b6cd-58c8307854d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:396: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `100` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["'Qual é o papel do presidente na Constituição Federal?;;; são são são — — — todas todas ca ca............ caso caso caso se se se dos dos vida vida vida pecado vida vida dos dos dos tão tão tão que que que pessoales pois pois pois sentido sentido sentidodosdosdos da da darrr foi foi foi um um um todo todo todo as as as entre entre seu seu seuororor pode o o o exemplo exemplo exemplo para para para ao ao ao não não nãodosdos isto isto isto às às às até até até caso caso com com com seus seus seus mas mas mas e e e quer quer quer nem nem nem tem tem tem parece parece parece instintos instintos instintos fala fala fala os os os na na na à à à na na quando quando quando uma uma uma quem quem quem-- forma forma fim fim fim meio meio meiosesese,,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# Exemplo de conversa\n","pergunta = \"Qual é o erro da moral?\"\n","resposta = gerar_resposta(pergunta, max_length=200, num_beams=8, no_repeat_ngram_size=3, top_k=100, top_p=0.95)\n","resposta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"id":"JG05_xpO2p4J","executionInfo":{"status":"ok","timestamp":1707096512098,"user_tz":180,"elapsed":443181,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"0627fa8f-15bc-4ffd-9698-50773cea9d88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:396: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `100` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["'Qual é o erro da moral? efeito efeito efeitotototo seu seu seu... muito muito muito \" \" \"iii contra contra contra da da da pouco pouco pouco linguagem linguagem linguagem até até caso caso casoina dessa dessa dessa::: necessário necessário necessário quando quando quando ainda ainda ainda razão razão razão moral moral moral esse esse esse humanidade humanidade humanidade\".\". estado estado estado na na na pela um um um tudo tudo tudo isso isso isso a a a estado estado\".\".\".,,, dos dos dos castraçãoismoismoismo ele ele qualquer qualquer qualquer toda toda toda forma forma forma representa representa representa espécie espécie espécie uma uma uma do do do e e e aos aos aos o o orara em em emdedede há há há--- no no no que que que sem sem sem porém porém porém não não não mais mais mais coisas coisas coisasááá de de de diz diz diz homem homem homem arte arte artemomomo,,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["# Função para recuperar documentos relevantes do VectorDB\n","def recuperar_documentos_relevantes(pergunta, num_documentos=5):\n","    documentos_relevantes = memory.search(pergunta, top_n=num_documentos)\n","    return [{'text': doc.get('text', doc.get('page_content', '')), 'origem': doc['metadata']['origem']} for doc in documentos_relevantes]"],"metadata":{"id":"RoQ8WCfvvA7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Função para gerar respostas com RAG\n","def gerar_resposta_rag(pergunta, num_documentos=5, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95):\n","    # Recuperar documentos relevantes\n","    documentos_relevantes = recuperar_documentos_relevantes(pergunta, num_documentos)\n","\n","    # Concatenar documentos relevantes para formar o contexto\n","    contexto = \" \".join([doc['text'] for doc in documentos_relevantes])\n","\n","    # Adicionar a pergunta ao contexto\n","    entrada_modelo = contexto + \" Pergunta: \" + pergunta\n","\n","    # Tokenizar a entrada\n","    tokens = tokenizer.encode(entrada_modelo, return_tensors=\"pt\")\n","\n","    # Obtendo a saída do modelo\n","    output = modelo.generate(tokens, max_length=max_length, num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size, top_k=top_k, top_p=top_p)\n","\n","    # Decodificando a saída\n","    resposta = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    return resposta"],"metadata":{"id":"YTRdIhdexwhV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Primeiro exemplo\n","pergunta = \"Qual é o papel do presidente na Constituição Federal?\"\n","resposta_rag = gerar_resposta_rag(pergunta)\n","resposta_rag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"X--ISp0ixzHc","executionInfo":{"status":"ok","timestamp":1707095613793,"user_tz":180,"elapsed":73075,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"75e54bab-c625-49f5-c1bc-dda9d03450eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'     Pergunta: Qual é o papel do presidente na Constituição Federal? \" \"..).).;; ideia ideia se setata e e primeiro primeiro um um vida vida dos dos tão tão tanto tanto in in não não mais mais de de humanidade humanidade vez vez sua suatotodosdos-- forma formaii a a maneira maneira os os na na que que'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# Segundo exemplo\n","pergunta = \"Qual é o erro da moral?\"\n","resposta_rag = gerar_resposta_rag(pergunta)\n","resposta_rag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"Nucx2QuE0b09","executionInfo":{"status":"ok","timestamp":1707096578459,"user_tz":180,"elapsed":66364,"user":{"displayName":"André Amorim","userId":"04859568826717067647"}},"outputId":"5cbcf4d2-48f6-4f7f-d532-7514d7660df5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'     Pergunta: Qual é o erro da moral? \" \" decadência decadênciaaa-- forma.. suas suas?? a seus seus humanidade humanidade homens homens até até caso caso se se coisas coisas ser sertt;; guerra que que cristã cristã diz diz uma umavv a a isso isso tempo tempo esta os os são são!!; nada nada um um às àsuu o o todas todas fazer fazeria,,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]}]}