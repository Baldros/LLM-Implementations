{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7gVOCTOiDut9"
      ],
      "authorship_tag": "ABX9TyO+8kQCQCJogRGEepgtGJcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baldros/Large-Language-Models/blob/main/OpenAI_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalações e Importações:\n",
        "\n",
        "Algumas bibliotecas, por padrão, não veem intaladas no ambiente virtual do colab, sendo assim é bom manter esse trecho e é necessário rodá-lo toda vez que se rodar o\n",
        "notebook pela primeira vez, assim como as importações:"
      ],
      "metadata": {
        "id": "E5ymAiHCQl7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcZelPFeQhIo",
        "outputId": "b839fc87-0fa0-4a01-d2e1-692c60fbf270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "# Instalações:\n",
        "!pip install requests\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações:\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "jHT-gY60TI1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuração da API:\n",
        "Antes de utilizar o modelo, precisamos configurar a utilização da API no nosso código. Aqui, apesar de acima, termos instalado a biblioteca, vamos trabalhar com requisição."
      ],
      "metadata": {
        "id": "JBpT-LdMQlBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# senha para autênticação:\n",
        "API_KEY = input(\"API KEY\")"
      ],
      "metadata": {
        "id": "0roD3XyxSZBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Nesse código, não vou utilizar as soluções da biblioteca openai, mas sim\n",
        "vou utilizar um método por links e tals. É como está sendo feito no tutorial e\n",
        "no momento eu to cansado demais pra ler documentação.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ByTqbSPSToIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# definição do dicionário de configurações:\n",
        "headers = {'Authorization': f'Bearer {API_KEY}','Content-Type':'application/json'}\n",
        "\n",
        "# Definindo o recebimento de dados:\n",
        "link = 'https://api.openai.com/v1/models'\n",
        "requisicao = requests.get(link,headers=headers) #get para pegar informação, post para enviar uma informação\n",
        "\n",
        "print(requisicao)\n",
        "#print(requisicao.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgaodMRIT1Oi",
        "outputId": "f03bfaee-4bba-4830-8396-148fcbd4520e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checando os modelos disponíveis:\n",
        "\n",
        "Como eu não sei exatamente quais modelos há, eu fiz esse trecho aqui pra checar.\n",
        "Eu sei que tem o gpt, que gera textos, mas não sei se tem o Dall-E, que gera imagens, e mais que isso, não sei quais são os modelos que eles disponibilizam, então, vamos checar."
      ],
      "metadata": {
        "id": "1JwCJTc5CXv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando os valores:\n",
        "dic = requisicao.json()\n",
        "\n",
        "lista_modelos = []\n",
        "for var in dic['data']:\n",
        "  lista_modelos.append(var['id'])"
      ],
      "metadata": {
        "id": "kCujWUpvWoxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'São {len(lista_modelos)} disponiveis até o momento\\n')\n",
        "print('modelos:\\n')\n",
        "display(lista_modelos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x7W-rJ-TZlMp",
        "outputId": "7a561b2b-911d-48c3-8791-3aa859785327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "São 64 disponiveis até o momento\n",
            "\n",
            "modelos:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['babbage',\n",
              " 'davinci',\n",
              " 'text-davinci-edit-001',\n",
              " 'babbage-code-search-code',\n",
              " 'text-similarity-babbage-001',\n",
              " 'code-davinci-edit-001',\n",
              " 'text-davinci-001',\n",
              " 'ada',\n",
              " 'babbage-code-search-text',\n",
              " 'babbage-similarity',\n",
              " 'code-search-babbage-text-001',\n",
              " 'text-curie-001',\n",
              " 'code-search-babbage-code-001',\n",
              " 'text-ada-001',\n",
              " 'text-embedding-ada-002',\n",
              " 'text-similarity-ada-001',\n",
              " 'curie-instruct-beta',\n",
              " 'gpt-3.5-turbo',\n",
              " 'ada-code-search-code',\n",
              " 'ada-similarity',\n",
              " 'code-search-ada-text-001',\n",
              " 'text-search-ada-query-001',\n",
              " 'gpt-3.5-turbo-0301',\n",
              " 'davinci-search-document',\n",
              " 'ada-code-search-text',\n",
              " 'text-search-ada-doc-001',\n",
              " 'davinci-instruct-beta',\n",
              " 'text-similarity-curie-001',\n",
              " 'code-search-ada-code-001',\n",
              " 'ada-search-query',\n",
              " 'text-search-davinci-query-001',\n",
              " 'curie-search-query',\n",
              " 'davinci-search-query',\n",
              " 'babbage-search-document',\n",
              " 'ada-search-document',\n",
              " 'text-search-curie-query-001',\n",
              " 'whisper-1',\n",
              " 'text-search-babbage-doc-001',\n",
              " 'curie-search-document',\n",
              " 'text-search-curie-doc-001',\n",
              " 'babbage-search-query',\n",
              " 'text-babbage-001',\n",
              " 'text-search-davinci-doc-001',\n",
              " 'text-search-babbage-query-001',\n",
              " 'curie-similarity',\n",
              " 'curie',\n",
              " 'text-davinci-003',\n",
              " 'text-similarity-davinci-001',\n",
              " 'text-davinci-002',\n",
              " 'davinci-similarity',\n",
              " 'cushman:2020-05-03',\n",
              " 'ada:2020-05-03',\n",
              " 'babbage:2020-05-03',\n",
              " 'curie:2020-05-03',\n",
              " 'davinci:2020-05-03',\n",
              " 'if-davinci-v2',\n",
              " 'if-curie-v2',\n",
              " 'if-davinci:3.0.0',\n",
              " 'davinci-if:3.0.0',\n",
              " 'davinci-instruct-beta:2.0.0',\n",
              " 'text-ada:001',\n",
              " 'text-davinci:001',\n",
              " 'text-curie:001',\n",
              " 'text-babbage:001']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando se DALL-E está disponivel:\n",
        "'DALL·E 2' in lista_modelos"
      ],
      "metadata": {
        "id": "K_4t214PYPbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e0e853-0737-45a1-c86e-b6fb5fc5bfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "  Não consegui identificar modelos relacionados a produção de imagem,\n",
        "infelizmente. Ainda não tive tempo de analisar todos os modelos,\n",
        "então, até o momento o que temos são coisas ligadas a produção de texto mesmo.\n",
        "😕\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QSiBQ7bEBsdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Montando o modelo conversacional:\n",
        "Para o primeiro caso, vamos trabalhar com o modelo 'gpt-3.5-turbo', porque é o que me parece mais atual e é o que eu conheço que sirva para os nossos propositos. Mais pra frente, com certeza podemos utilizar outros modelos que nos sejam uteis também."
      ],
      "metadata": {
        "id": "7gVOCTOiDut9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo Modelo:\n",
        "id_model = 'gpt-3.5-turbo'\n",
        "\n",
        "# Escrenvendo a mensagem:\n",
        "mensagem = input('Digite sua mensagem:\\n')\n",
        "# mensagem = \" \"\n",
        "\n",
        "# Request Body\n",
        "body_mensagem = {\n",
        "    'model':id_model,\n",
        "    'messages':[{\"role\":'user','content':mensagem}]\n",
        "}\n",
        "\n",
        "body_mensagem = json.dumps(body_mensagem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpVorKLLFzUP",
        "outputId": "6b74a2b8-1b66-49e1-f489-96cf65d5dcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite sua mensagem:\n",
            "Faça uma resumo do livro \"Punho de Deus\" de Frederick Forsyth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Nota:\n",
        "  O método POST envia dados no corpo da solicitação HTTP, enquanto o método GET\n",
        "envia dados na URL. Como resultado, as solicitações POST são usadas quando é\n",
        "necessário enviar grandes quantidades de dados, como formulários de inscrição,\n",
        "mensagens de email ou arquivos de upload, e as solicitações GET são usadas para\n",
        "solicitar recursos de um servidor.\n",
        "\n",
        "  Além disso, os dados enviados por uma solicitação POST não são visíveis na\n",
        "URL, enquanto os dados enviados por uma solicitação GET são visíveis na URL.\n",
        "Como resultado, as solicitações POST são mais seguras e mais adequadas para\n",
        "enviar informações confidenciais, como senhas ou informações de pagamento.\n",
        "\n",
        "  Em resumo, enquanto as solicitações GET são usadas para recuperar dados, as\n",
        "solicitações POST são usadas para enviar dados.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "r4gBCTBWGEyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o envio de dados:\n",
        "link = 'https://api.openai.com/v1/chat/completions'\n",
        "requisicao = requests.post(link,headers=headers, data=body_mensagem)\n",
        "print(requisicao)\n",
        "display(requisicao.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ZF-4cJCRD36d",
        "outputId": "e930db36-8d30-4560-f5b9-d2877b3f8e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{\"id\":\"chatcmpl-7BjZVo1z7rgA1tuv8Bht7xWGimrcf\",\"object\":\"chat.completion\",\"created\":1683031141,\"model\":\"gpt-3.5-turbo-0301\",\"usage\":{\"prompt_tokens\":26,\"completion_tokens\":356,\"total_tokens\":382},\"choices\":[{\"message\":{\"role\":\"assistant\",\"content\":\"\\\\\"Punho de Deus\\\\\" é um thriller político que se passa na Inglaterra durante a Guerra Fria. A história começa quando um jovem inglês, Steve Devereaux, é recrutado pelo serviço secreto britânico para uma missão na União Soviética. Sua tarefa é se infiltrar no país comunista e localizar um cientista que pode ter desenvolvido uma arma secreta chamada \\\\\"Punho de Deus\\\\\", capaz de causar devastação total.\\\\n\\\\nEnquanto Devereaux se prepara para a missão, um grupo de políticos britânicos planeja um acordo com os soviéticos que pode mudar o rumo da guerra. Mas o serviço secreto acredita que o acordo é uma armadilha e que os soviéticos não têm intenção de cumprir suas promessas.\\\\n\\\\nAo chegar na União Soviética, Devereaux enfrenta inúmeros obstáculos e desafios, incluindo a desconfiança de seus próprios colegas. No entanto, ele consegue encontrar o cientista e descobrir que a verdadeira arma secreta é muito diferente do que foi relatado pelos serviços de inteligência britânicos.\\\\n\\\\nNo final, Devereaux e sua equipe conseguem impedir que o acordo político seja assinado e desmantelar a base onde a arma secreta estava localizada. \\\\\"Punho de Deus\\\\\" é uma história emocionante e cheia de reviravoltas, explorando a tensão entre os países durante a Guerra Fria e os riscos envolvidos na espionagem.\"},\"finish_reason\":\"stop\",\"index\":0}]}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = requisicao.json()\n",
        "mensagem = resposta['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "9MUXdrnqGvRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(mensagem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "MXpT5zetQeGf",
        "outputId": "518fc8a4-b296-445b-be0c-57760843a44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\"Punho de Deus\" é um thriller político que se passa na Inglaterra durante a Guerra Fria. A história começa quando um jovem inglês, Steve Devereaux, é recrutado pelo serviço secreto britânico para uma missão na União Soviética. Sua tarefa é se infiltrar no país comunista e localizar um cientista que pode ter desenvolvido uma arma secreta chamada \"Punho de Deus\", capaz de causar devastação total.\\n\\nEnquanto Devereaux se prepara para a missão, um grupo de políticos britânicos planeja um acordo com os soviéticos que pode mudar o rumo da guerra. Mas o serviço secreto acredita que o acordo é uma armadilha e que os soviéticos não têm intenção de cumprir suas promessas.\\n\\nAo chegar na União Soviética, Devereaux enfrenta inúmeros obstáculos e desafios, incluindo a desconfiança de seus próprios colegas. No entanto, ele consegue encontrar o cientista e descobrir que a verdadeira arma secreta é muito diferente do que foi relatado pelos serviços de inteligência britânicos.\\n\\nNo final, Devereaux e sua equipe conseguem impedir que o acordo político seja assinado e desmantelar a base onde a arma secreta estava localizada. \"Punho de Deus\" é uma história emocionante e cheia de reviravoltas, explorando a tensão entre os países durante a Guerra Fria e os riscos envolvidos na espionagem.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oSaIJIV9RbH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
